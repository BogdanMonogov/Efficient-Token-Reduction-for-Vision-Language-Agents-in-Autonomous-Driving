{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2f8ce28f23dc44eeae63060f01a7faf1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ce559e9b878d4cab873edb53d34d5b6f",
              "IPY_MODEL_072f21514660489991f67ada126f3943",
              "IPY_MODEL_fbf4c09f291944b99e86247605385003"
            ],
            "layout": "IPY_MODEL_59a98573bd4848b386002606a48ae205"
          }
        },
        "ce559e9b878d4cab873edb53d34d5b6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5756e96951db44d0b31aaf89e82164c4",
            "placeholder": "​",
            "style": "IPY_MODEL_ba21769828984e42b3f78212fdaaa467",
            "value": "moving_count.json: "
          }
        },
        "072f21514660489991f67ada126f3943": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_695e7ff67d064841bf33d8b1e7c55eb3",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b58b21c86fd34b0fb2d1317b111f8cd0",
            "value": 1
          }
        },
        "fbf4c09f291944b99e86247605385003": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b9dd986a0e184c3aac38b29a70f82c04",
            "placeholder": "​",
            "style": "IPY_MODEL_4ae342cab3614ae39a36721bb0ba1ba6",
            "value": " 27.9k/? [00:00&lt;00:00, 1.82MB/s]"
          }
        },
        "59a98573bd4848b386002606a48ae205": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5756e96951db44d0b31aaf89e82164c4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ba21769828984e42b3f78212fdaaa467": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "695e7ff67d064841bf33d8b1e7c55eb3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "b58b21c86fd34b0fb2d1317b111f8cd0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b9dd986a0e184c3aac38b29a70f82c04": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4ae342cab3614ae39a36721bb0ba1ba6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "548978b1ecf44d0cb6e44ac78f59ca47": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b93d7420b02b4170bcdef01e9edd4907",
              "IPY_MODEL_b7746a216e9a44cc987587a540dccb77",
              "IPY_MODEL_dd7952fe331e440eac2ed0bdfdf1bf6a"
            ],
            "layout": "IPY_MODEL_63dcb10ac67949dc8c729a9ed6079a8a"
          }
        },
        "b93d7420b02b4170bcdef01e9edd4907": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9480764a00d046c0a1592bd7ba9e8c3e",
            "placeholder": "​",
            "style": "IPY_MODEL_1f169a780eeb44eea8e4f869ae033176",
            "value": "video/clevrer.zip: 100%"
          }
        },
        "b7746a216e9a44cc987587a540dccb77": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1d6d9148c0114faebd7593ed1b95368f",
            "max": 1123944836,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5d1b64149acd41d8af2068750cc56950",
            "value": 1123944836
          }
        },
        "dd7952fe331e440eac2ed0bdfdf1bf6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_052d0d2df848417c884b6a93b9c0c81d",
            "placeholder": "​",
            "style": "IPY_MODEL_a66bcba3be194471b31e4f90630a0461",
            "value": " 1.12G/1.12G [00:17&lt;00:00, 55.0MB/s]"
          }
        },
        "63dcb10ac67949dc8c729a9ed6079a8a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9480764a00d046c0a1592bd7ba9e8c3e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1f169a780eeb44eea8e4f869ae033176": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1d6d9148c0114faebd7593ed1b95368f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5d1b64149acd41d8af2068750cc56950": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "052d0d2df848417c884b6a93b9c0c81d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a66bcba3be194471b31e4f90630a0461": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "47119ee2f43242eea088271bce2ab4e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_470168b4b4d949ed984d7a44a9d667b2",
              "IPY_MODEL_164be652d6f54b4ea73a6c4a08e2d2f4",
              "IPY_MODEL_e7cfe5724304425fa3c4b7f03dc00567"
            ],
            "layout": "IPY_MODEL_1dd30a5c4fde4bc18b9c1ef609b9589e"
          }
        },
        "470168b4b4d949ed984d7a44a9d667b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aaa8d978c89247e6a385ee1260427894",
            "placeholder": "​",
            "style": "IPY_MODEL_61031c8937614b27be5a788a3d1e93c0",
            "value": "Generating train split: "
          }
        },
        "164be652d6f54b4ea73a6c4a08e2d2f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_84ee9c4380eb45e1868784f21accb61c",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_27c51b9ec3f84b4f88baefc265c68149",
            "value": 1
          }
        },
        "e7cfe5724304425fa3c4b7f03dc00567": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f988a1472ebe4d6c9b293a5b4ef07f8d",
            "placeholder": "​",
            "style": "IPY_MODEL_a6a1d538b423454cbaef92ff1b72949d",
            "value": " 200/0 [00:00&lt;00:00, 3137.62 examples/s]"
          }
        },
        "1dd30a5c4fde4bc18b9c1ef609b9589e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aaa8d978c89247e6a385ee1260427894": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "61031c8937614b27be5a788a3d1e93c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "84ee9c4380eb45e1868784f21accb61c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "27c51b9ec3f84b4f88baefc265c68149": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f988a1472ebe4d6c9b293a5b4ef07f8d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a6a1d538b423454cbaef92ff1b72949d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8SV2RhfxHCSM",
        "outputId": "a234d9f9-f620-4101-879f-153d580afbb5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'LLaVA-Scissor'...\n",
            "remote: Enumerating objects: 237, done.\u001b[K\n",
            "remote: Counting objects: 100% (237/237), done.\u001b[K\n",
            "remote: Compressing objects: 100% (231/231), done.\u001b[K\n",
            "remote: Total 237 (delta 70), reused 3 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (237/237), 1.95 MiB | 6.23 MiB/s, done.\n",
            "Resolving deltas: 100% (70/70), done.\n",
            "total 20\n",
            "drwxr-xr-x 1 root root 4096 Oct 19 13:32 .\n",
            "drwxr-xr-x 1 root root 4096 Oct 19 13:30 ..\n",
            "drwxr-xr-x 4 root root 4096 Oct 16 13:41 .config\n",
            "drwxr-xr-x 7 root root 4096 Oct 19 13:32 LLaVA-Scissor\n",
            "drwxr-xr-x 1 root root 4096 Oct 16 13:41 sample_data\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "!git clone https://github.com/HumanMLLM/LLaVA-Scissor.git\n",
        "!ls -la"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sys.path.append('./LLaVA-Scissor')"
      ],
      "metadata": {
        "id": "D9nwtXlpSYbc"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Install decord and other video processing libraries\n",
        "!pip install decord\n",
        "!pip install av\n",
        "!pip install pyav\n",
        "!pip install opencv-python\n",
        "!pip install moviepy\n",
        "\n",
        "# Also install the core dependencies\n",
        "!pip install \"accelerate==0.28.0\"\n",
        "!pip install matplotlib huggingface_hub\n",
        "!pip install \"transformers==4.37.2\"\n",
        "!pip install \"torch==2.1.2\" \"torchvision==0.16.2\"\n",
        "!pip install \"pillow>=9.0.0\"\n",
        "!pip install \"numpy>=1.21.0\"\n",
        "!pip install \"open-clip-torch>=2.20.0\"\n",
        "!pip install \"datasets==2.16.1\"\n",
        "\n",
        "# Install the package in development mode\n",
        "!cd /content/LLaVA-Scissor && pip install -e .[train]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A8wSNLs5T8xe",
        "outputId": "0a9d5c45-2e16-49a6-da08-4d91230ed7f7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting decord\n",
            "  Downloading decord-0.6.0-py3-none-manylinux2010_x86_64.whl.metadata (422 bytes)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.12/dist-packages (from decord) (2.0.2)\n",
            "Downloading decord-0.6.0-py3-none-manylinux2010_x86_64.whl (13.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.6/13.6 MB\u001b[0m \u001b[31m62.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: decord\n",
            "Successfully installed decord-0.6.0\n",
            "Collecting av\n",
            "  Downloading av-16.0.1-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (4.6 kB)\n",
            "Downloading av-16.0.1-cp312-cp312-manylinux_2_28_x86_64.whl (40.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.5/40.5 MB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: av\n",
            "Successfully installed av-16.0.1\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement pyav (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for pyav\u001b[0m\u001b[31m\n",
            "\u001b[0mRequirement already satisfied: opencv-python in /usr/local/lib/python3.12/dist-packages (4.12.0.88)\n",
            "Requirement already satisfied: numpy<2.3.0,>=2 in /usr/local/lib/python3.12/dist-packages (from opencv-python) (2.0.2)\n",
            "Requirement already satisfied: moviepy in /usr/local/lib/python3.12/dist-packages (1.0.3)\n",
            "Requirement already satisfied: decorator<5.0,>=4.0.2 in /usr/local/lib/python3.12/dist-packages (from moviepy) (4.4.2)\n",
            "Requirement already satisfied: tqdm<5.0,>=4.11.2 in /usr/local/lib/python3.12/dist-packages (from moviepy) (4.67.1)\n",
            "Requirement already satisfied: requests<3.0,>=2.8.1 in /usr/local/lib/python3.12/dist-packages (from moviepy) (2.32.4)\n",
            "Requirement already satisfied: proglog<=1.0.0 in /usr/local/lib/python3.12/dist-packages (from moviepy) (0.1.12)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.12/dist-packages (from moviepy) (2.0.2)\n",
            "Requirement already satisfied: imageio<3.0,>=2.5 in /usr/local/lib/python3.12/dist-packages (from moviepy) (2.37.0)\n",
            "Requirement already satisfied: imageio-ffmpeg>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from moviepy) (0.6.0)\n",
            "Requirement already satisfied: pillow>=8.3.2 in /usr/local/lib/python3.12/dist-packages (from imageio<3.0,>=2.5->moviepy) (11.3.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0,>=2.8.1->moviepy) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0,>=2.8.1->moviepy) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0,>=2.8.1->moviepy) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0,>=2.8.1->moviepy) (2025.10.5)\n",
            "Collecting accelerate==0.28.0\n",
            "  Downloading accelerate-0.28.0-py3-none-any.whl.metadata (18 kB)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from accelerate==0.28.0) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from accelerate==0.28.0) (25.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate==0.28.0) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from accelerate==0.28.0) (6.0.3)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.12/dist-packages (from accelerate==0.28.0) (2.8.0+cu126)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.12/dist-packages (from accelerate==0.28.0) (0.35.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.12/dist-packages (from accelerate==0.28.0) (0.6.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.28.0) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.28.0) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.28.0) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.28.0) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.28.0) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.28.0) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.28.0) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.28.0) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.28.0) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.28.0) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.28.0) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.28.0) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.28.0) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.28.0) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.28.0) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.28.0) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.28.0) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.28.0) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.28.0) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.28.0) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.28.0) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.28.0) (3.4.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface-hub->accelerate==0.28.0) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub->accelerate==0.28.0) (4.67.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub->accelerate==0.28.0) (1.1.10)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.10.0->accelerate==0.28.0) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.10.0->accelerate==0.28.0) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub->accelerate==0.28.0) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub->accelerate==0.28.0) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub->accelerate==0.28.0) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub->accelerate==0.28.0) (2025.10.5)\n",
            "Downloading accelerate-0.28.0-py3-none-any.whl (290 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m290.1/290.1 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: accelerate\n",
            "  Attempting uninstall: accelerate\n",
            "    Found existing installation: accelerate 1.10.1\n",
            "    Uninstalling accelerate-1.10.1:\n",
            "      Successfully uninstalled accelerate-1.10.1\n",
            "Successfully installed accelerate-0.28.0\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.12/dist-packages (0.35.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (3.20.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (2025.3.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (6.0.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (1.1.10)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub) (2025.10.5)\n",
            "Collecting transformers==4.37.2\n",
            "  Downloading transformers-4.37.2-py3-none-any.whl.metadata (129 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.4/129.4 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers==4.37.2) (3.20.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.12/dist-packages (from transformers==4.37.2) (0.35.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers==4.37.2) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers==4.37.2) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers==4.37.2) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers==4.37.2) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers==4.37.2) (2.32.4)\n",
            "Collecting tokenizers<0.19,>=0.14 (from transformers==4.37.2)\n",
            "  Downloading tokenizers-0.15.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.12/dist-packages (from transformers==4.37.2) (0.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers==4.37.2) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.37.2) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.37.2) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.37.2) (1.1.10)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.37.2) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.37.2) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.37.2) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.37.2) (2025.10.5)\n",
            "Downloading transformers-4.37.2-py3-none-any.whl (8.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.4/8.4 MB\u001b[0m \u001b[31m102.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tokenizers-0.15.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m127.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tokenizers, transformers\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.22.1\n",
            "    Uninstalling tokenizers-0.22.1:\n",
            "      Successfully uninstalled tokenizers-0.22.1\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.57.1\n",
            "    Uninstalling transformers-4.57.1:\n",
            "      Successfully uninstalled transformers-4.57.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "sentence-transformers 5.1.1 requires transformers<5.0.0,>=4.41.0, but you have transformers 4.37.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed tokenizers-0.15.2 transformers-4.37.2\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement torch==2.1.2 (from versions: 2.2.0, 2.2.1, 2.2.2, 2.3.0, 2.3.1, 2.4.0, 2.4.1, 2.5.0, 2.5.1, 2.6.0, 2.7.0, 2.7.1, 2.8.0, 2.9.0)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for torch==2.1.2\u001b[0m\u001b[31m\n",
            "\u001b[0mRequirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.12/dist-packages (11.3.0)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Collecting open-clip-torch>=2.20.0\n",
            "  Downloading open_clip_torch-3.2.0-py3-none-any.whl.metadata (32 kB)\n",
            "Requirement already satisfied: torch>=2.0 in /usr/local/lib/python3.12/dist-packages (from open-clip-torch>=2.20.0) (2.8.0+cu126)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (from open-clip-torch>=2.20.0) (0.23.0+cu126)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.12/dist-packages (from open-clip-torch>=2.20.0) (2024.11.6)\n",
            "Collecting ftfy (from open-clip-torch>=2.20.0)\n",
            "  Downloading ftfy-6.3.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from open-clip-torch>=2.20.0) (4.67.1)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.12/dist-packages (from open-clip-torch>=2.20.0) (0.35.3)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.12/dist-packages (from open-clip-torch>=2.20.0) (0.6.2)\n",
            "Requirement already satisfied: timm>=1.0.17 in /usr/local/lib/python3.12/dist-packages (from open-clip-torch>=2.20.0) (1.0.20)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from timm>=1.0.17->open-clip-torch>=2.20.0) (6.0.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->open-clip-torch>=2.20.0) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->open-clip-torch>=2.20.0) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->open-clip-torch>=2.20.0) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->open-clip-torch>=2.20.0) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->open-clip-torch>=2.20.0) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->open-clip-torch>=2.20.0) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->open-clip-torch>=2.20.0) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->open-clip-torch>=2.20.0) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->open-clip-torch>=2.20.0) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->open-clip-torch>=2.20.0) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->open-clip-torch>=2.20.0) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->open-clip-torch>=2.20.0) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->open-clip-torch>=2.20.0) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->open-clip-torch>=2.20.0) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->open-clip-torch>=2.20.0) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->open-clip-torch>=2.20.0) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->open-clip-torch>=2.20.0) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->open-clip-torch>=2.20.0) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->open-clip-torch>=2.20.0) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->open-clip-torch>=2.20.0) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->open-clip-torch>=2.20.0) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->open-clip-torch>=2.20.0) (3.4.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.12/dist-packages (from ftfy->open-clip-torch>=2.20.0) (0.2.14)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub->open-clip-torch>=2.20.0) (25.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface-hub->open-clip-torch>=2.20.0) (2.32.4)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub->open-clip-torch>=2.20.0) (1.1.10)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision->open-clip-torch>=2.20.0) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision->open-clip-torch>=2.20.0) (11.3.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.0->open-clip-torch>=2.20.0) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.0->open-clip-torch>=2.20.0) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub->open-clip-torch>=2.20.0) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub->open-clip-torch>=2.20.0) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub->open-clip-torch>=2.20.0) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub->open-clip-torch>=2.20.0) (2025.10.5)\n",
            "Downloading open_clip_torch-3.2.0-py3-none-any.whl (1.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m31.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ftfy-6.3.1-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: ftfy, open-clip-torch\n",
            "Successfully installed ftfy-6.3.1 open-clip-torch-3.2.0\n",
            "Collecting datasets==2.16.1\n",
            "  Downloading datasets-2.16.1-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets==2.16.1) (3.20.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from datasets==2.16.1) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets==2.16.1) (18.1.0)\n",
            "Collecting pyarrow-hotfix (from datasets==2.16.1)\n",
            "  Downloading pyarrow_hotfix-0.7-py3-none-any.whl.metadata (3.6 kB)\n",
            "Collecting dill<0.3.8,>=0.3.0 (from datasets==2.16.1)\n",
            "  Downloading dill-0.3.7-py3-none-any.whl.metadata (9.9 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets==2.16.1) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.12/dist-packages (from datasets==2.16.1) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.12/dist-packages (from datasets==2.16.1) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets==2.16.1) (3.6.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.12/dist-packages (from datasets==2.16.1) (0.70.16)\n",
            "Collecting fsspec<=2023.10.0,>=2023.1.0 (from fsspec[http]<=2023.10.0,>=2023.1.0->datasets==2.16.1)\n",
            "  Downloading fsspec-2023.10.0-py3-none-any.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.12/dist-packages (from datasets==2.16.1) (3.13.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.4 in /usr/local/lib/python3.12/dist-packages (from datasets==2.16.1) (0.35.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from datasets==2.16.1) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from datasets==2.16.1) (6.0.3)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets==2.16.1) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets==2.16.1) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets==2.16.1) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets==2.16.1) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets==2.16.1) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets==2.16.1) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets==2.16.1) (1.22.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.19.4->datasets==2.16.1) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.19.4->datasets==2.16.1) (1.1.10)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->datasets==2.16.1) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->datasets==2.16.1) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->datasets==2.16.1) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->datasets==2.16.1) (2025.10.5)\n",
            "INFO: pip is looking at multiple versions of multiprocess to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting multiprocess (from datasets==2.16.1)\n",
            "  Downloading multiprocess-0.70.18-py312-none-any.whl.metadata (7.5 kB)\n",
            "  Downloading multiprocess-0.70.17-py312-none-any.whl.metadata (7.2 kB)\n",
            "  Downloading multiprocess-0.70.15-py311-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets==2.16.1) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets==2.16.1) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets==2.16.1) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets==2.16.1) (1.17.0)\n",
            "Downloading datasets-2.16.1-py3-none-any.whl (507 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m507.1/507.1 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.7-py3-none-any.whl (115 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2023.10.0-py3-none-any.whl (166 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.4/166.4 kB\u001b[0m \u001b[31m21.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.15-py311-none-any.whl (135 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.4/135.4 kB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyarrow_hotfix-0.7-py3-none-any.whl (7.9 kB)\n",
            "Installing collected packages: pyarrow-hotfix, fsspec, dill, multiprocess, datasets\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2025.3.0\n",
            "    Uninstalling fsspec-2025.3.0:\n",
            "      Successfully uninstalled fsspec-2025.3.0\n",
            "  Attempting uninstall: dill\n",
            "    Found existing installation: dill 0.3.8\n",
            "    Uninstalling dill-0.3.8:\n",
            "      Successfully uninstalled dill-0.3.8\n",
            "  Attempting uninstall: multiprocess\n",
            "    Found existing installation: multiprocess 0.70.16\n",
            "    Uninstalling multiprocess-0.70.16:\n",
            "      Successfully uninstalled multiprocess-0.70.16\n",
            "  Attempting uninstall: datasets\n",
            "    Found existing installation: datasets 4.0.0\n",
            "    Uninstalling datasets-4.0.0:\n",
            "      Successfully uninstalled datasets-4.0.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2023.10.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-2.16.1 dill-0.3.7 fsspec-2023.10.0 multiprocess-0.70.15 pyarrow-hotfix-0.7\n",
            "Obtaining file:///content/LLaVA-Scissor\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Checking if build backend supports build_editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing editable metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting transformers@ git+https://github.com/huggingface/transformers.git@1c39974a4c4036fd641bc1191cc32799f85715a4 (from llava==1.7.0.dev0)\n",
            "  Cloning https://github.com/huggingface/transformers.git (to revision 1c39974a4c4036fd641bc1191cc32799f85715a4) to /tmp/pip-install-djvta593/transformers_db98c9c7451d43379a5f6652428f5d7b\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers.git /tmp/pip-install-djvta593/transformers_db98c9c7451d43379a5f6652428f5d7b\n",
            "  Running command git rev-parse -q --verify 'sha^1c39974a4c4036fd641bc1191cc32799f85715a4'\n",
            "  Running command git fetch -q https://github.com/huggingface/transformers.git 1c39974a4c4036fd641bc1191cc32799f85715a4\n",
            "  Running command git checkout -q 1c39974a4c4036fd641bc1191cc32799f85715a4\n",
            "  Resolved https://github.com/huggingface/transformers.git to commit 1c39974a4c4036fd641bc1191cc32799f85715a4\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting numpy==1.26.1 (from llava==1.7.0.dev0)\n",
            "  Downloading numpy-1.26.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.2/61.2 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: open_clip_torch in /usr/local/lib/python3.12/dist-packages (from llava==1.7.0.dev0) (3.2.0)\n",
            "Requirement already satisfied: fastapi in /usr/local/lib/python3.12/dist-packages (from llava==1.7.0.dev0) (0.119.0)\n",
            "Collecting markdown2[all] (from llava==1.7.0.dev0)\n",
            "  Downloading markdown2-2.5.4-py3-none-any.whl.metadata (2.1 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from llava==1.7.0.dev0) (2.32.4)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.12/dist-packages (from llava==1.7.0.dev0) (0.2.1)\n",
            "INFO: pip is looking at multiple versions of llava[train] to determine which version is compatible with other requirements. This could take a while.\n",
            "\u001b[31mERROR: Ignored the following versions that require a different python version: 1.21.2 Requires-Python >=3.7,<3.11; 1.21.3 Requires-Python >=3.7,<3.11; 1.21.4 Requires-Python >=3.7,<3.11; 1.21.5 Requires-Python >=3.7,<3.11; 1.21.6 Requires-Python >=3.7,<3.11\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement torch==2.1.2; extra == \"train\" (from llava[train]) (from versions: 2.2.0, 2.2.1, 2.2.2, 2.3.0, 2.3.1, 2.4.0, 2.4.1, 2.5.0, 2.5.1, 2.6.0, 2.7.0, 2.7.1, 2.8.0, 2.9.0)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for torch==2.1.2; extra == \"train\"\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import os\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from llava.model.builder import load_pretrained_model\n",
        "from llava.mm_utils import get_model_name_from_path, process_images, tokenizer_image_token\n",
        "from llava.constants import IMAGE_TOKEN_INDEX, DEFAULT_IMAGE_TOKEN, DEFAULT_IM_START_TOKEN, DEFAULT_IM_END_TOKEN, IGNORE_INDEX\n",
        "from llava.conversation import conv_templates, SeparatorStyle\n",
        "from huggingface_hub import snapshot_download, hf_hub_download\n",
        "import bisect\n",
        "import shutil\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import requests\n",
        "import copy\n",
        "import warnings\n",
        "from decord import VideoReader, cpu\n",
        "from datasets import load_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4tiyyduaRcbu",
        "outputId": "7cd63dcb-833b-4c33-bc2f-05d7e5a1a90c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/LLaVA-Scissor/llava/model/llava_arch.py:217: SyntaxWarning: \"is not\" with 'int' literal. Did you mean \"!=\"?\n",
            "  if slower_img_feat is not 0:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "from .language_model.llava_llama import LlavaLlamaForCausalLM, LlavaConfig\n",
            "from .language_model.llava_qwen import LlavaQwenForCausalLM, LlavaQwenConfig\n",
            "from .language_model.llava_mistral import LlavaMistralForCausalLM, LlavaMistralConfig\n",
            "from .language_model.llava_mixtral import LlavaMixtralForCausalLM, LlavaMixtralConfig\n",
            "from .language_model.llava_qwen_zip import LlavaQwenZipForCausalLM, LlavaQwenZipConfig\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/LLaVA-Scissor/llava/model/llava_arch_zip.py:320: SyntaxWarning: \"is not\" with 'int' literal. Did you mean \"!=\"?\n",
            "  if slower_img_feat is not 0:\n",
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_list = {\n",
        "    \"Action Sequence\": (\"action_sequence.json\", \"star/Charades_v1_480/\", \"video\", True), # has start & end\n",
        "    \"Action Prediction\": (\"action_prediction.json\", \"star/Charades_v1_480/\", \"video\", True), # has start & end\n",
        "    \"Action Antonym\": (\"action_antonym.json\", \"ssv2_video/\", \"video\", False),\n",
        "    \"Fine-grained Action\": (\"fine_grained_action.json\", \"Moments_in_Time_Raw/videos/\", \"video\", False),\n",
        "    \"Unexpected Action\": (\"unexpected_action.json\", \"FunQA_test/test/\", \"video\", False),\n",
        "    \"Object Existence\": (\"object_existence.json\", \"clevrer/video_validation/\", \"video\", False),\n",
        "    \"Object Interaction\": (\"object_interaction.json\", \"star/Charades_v1_480/\", \"video\", True), # has start & end\n",
        "    \"Object Shuffle\": (\"object_shuffle.json\", \"perception/videos/\", \"video\", False),\n",
        "    \"Moving Direction\": (\"moving_direction.json\", \"clevrer/video_validation/\", \"video\", False),\n",
        "    \"Action Localization\": (\"action_localization.json\", \"sta/sta_video/\", \"video\", True),  # has start & end\n",
        "    \"Scene Transition\": (\"scene_transition.json\", \"scene_qa/video/\", \"video\", False),\n",
        "    \"Action Count\": (\"action_count.json\", \"perception/videos/\", \"video\", False),\n",
        "    \"Moving Count\": (\"moving_count.json\", \"clevrer/video_validation/\", \"video\", False),\n",
        "    \"Moving Attribute\": (\"moving_attribute.json\", \"clevrer/video_validation/\", \"video\", False),\n",
        "    \"State Change\": (\"state_change.json\", \"perception/videos/\", \"video\", False),\n",
        "    \"Fine-grained Pose\": (\"fine_grained_pose.json\", \"nturgbd/\", \"video\", False),\n",
        "    \"Character Order\": (\"character_order.json\", \"perception/videos/\", \"video\", False),\n",
        "    \"Egocentric Navigation\": (\"egocentric_navigation.json\", \"vlnqa/\", \"video\", False),\n",
        "    \"Episodic Reasoning\": (\"episodic_reasoning.json\", \"tvqa/frames_fps3_hq/\", \"frame\", True),  # has start & end, read frame\n",
        "    \"Counterfactual Inference\": (\"counterfactual_inference.json\", \"clevrer/video_validation/\", \"video\", False),\n",
        "}\n",
        "\n",
        "data_dir = \"dataset\"\n",
        "if not os.path.exists(data_dir):\n",
        "    os.mkdir(\"dataset\")\n",
        "\n",
        "def read_video_pyav(video_path, start, end, n_frames=8):\n",
        "    \"\"\"\n",
        "    Reads a video for given start-end timestamps interval\n",
        "    and uniformly samples 8 frames of it\n",
        "    \"\"\"\n",
        "    container = av.open(video_path)\n",
        "    video = container.streams.get(0)[0]\n",
        "\n",
        "    av_timestamps = [\n",
        "        int(packet.pts * video.time_base) for packet in container.demux(video) if packet.pts is not None\n",
        "    ]\n",
        "\n",
        "    av_timestamps.sort()\n",
        "    start_id = bisect.bisect_left(av_timestamps, start)\n",
        "    end_id = bisect.bisect_left(av_timestamps, end)\n",
        "\n",
        "    # in case it is a very short video, lets take a longer duration and sample\n",
        "    if end_id  - start_id < 10:\n",
        "        end_id += 10\n",
        "        start_id -= 10\n",
        "\n",
        "    end_id = min(len(av_timestamps) - 1, end_id)\n",
        "    start_id = max(1, start_id)\n",
        "\n",
        "    # We sample n_frames frames for tuning following the original paper\n",
        "    # But we can increase the number of frames for longer videos and check out if it helps performance\n",
        "    # Change the below \"n_frames\" to any number of frames you want, and note that more frames -> more computational resources needed\n",
        "    indices = np.linspace(start_id, end_id, n_frames).astype(int)\n",
        "\n",
        "    frames = []\n",
        "    container.seek(0)\n",
        "    for i, frame in enumerate(container.decode(video=0)):\n",
        "        if i > end_id:\n",
        "            break\n",
        "        if i >= start_id and i in indices:\n",
        "            frames.append(frame)\n",
        "    assert len(frames) == n_frames, f\"Got {len(frames)} frames but should be {n_frames}. Check the indices: {indices};, start_id: {start_id}, end_id: {end_id}. Len of video is {len(av_timestamps)} frames.\"\n",
        "    return np.stack([x.to_ndarray(format=\"rgb24\") for x in frames])\n",
        "\n",
        "def collate_read_video(example, path):\n",
        "    # Some datasets have a start-end interval, so we try to get it if exists.\n",
        "    # Otherwise just set a very large end timestamp\n",
        "    clip = read_video_pyav(f'{path}/{example[\"video\"]}', example.get(\"start\", 1), example.get(\"end\", 1e+10))\n",
        "    example[\"clip\"] = clip\n",
        "    return example\n",
        "\n",
        "TASK_NAME = \"Moving Count\"\n",
        "annotation_fn, video_dir, video_type, has_clip = data_list[TASK_NAME]\n",
        "\n",
        "annotation_fn_local = hf_hub_download(\n",
        "    repo_id=\"OpenGVLab/MVBench\",\n",
        "    filename='json/' + annotation_fn,\n",
        "    repo_type=\"dataset\",\n",
        "    local_dir=data_dir\n",
        ")\n",
        "\n",
        "video_zip_name = video_dir.split(\"/\")[0] + \".zip\"\n",
        "videos_zip = hf_hub_download(\n",
        "    repo_id=\"OpenGVLab/MVBench\",\n",
        "    filename='video/' + video_zip_name,\n",
        "    repo_type=\"dataset\",\n",
        "    local_dir=data_dir\n",
        ")\n",
        "\n",
        "for zip_file in os.listdir(f\"{data_dir}/video\"):\n",
        "    if zip_file.endswith(\".zip\"):\n",
        "        shutil.unpack_archive(\n",
        "            f\"{data_dir}/video/{zip_file}\",\n",
        "            f\"{data_dir}/video/videos_unzipped/\"\n",
        "        )\n",
        "\n",
        "ds = load_dataset(\"json\", data_files=annotation_fn_local, split=\"train\")\n",
        "ds\n",
        "\n",
        "has_missing = False\n",
        "for sample in ds:\n",
        "    if not os.path.exists(f\"{data_dir}/video/videos_unzipped/{video_dir}/{sample['video']}\"):\n",
        "        print(f\"Video `{sample['video']}` does not exists!\")\n",
        "        has_missing = True\n",
        "\n",
        "print(f\"Dataset length = {len(ds)}\")\n",
        "if has_missing:\n",
        "    ds = ds.filter(lambda x: os.path.exists(f\"{data_dir}/video/videos_unzipped/{video_dir}/{x['video']}\"))\n",
        "\n",
        "print(f\"Dataset length = {len(ds)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 148,
          "referenced_widgets": [
            "2f8ce28f23dc44eeae63060f01a7faf1",
            "ce559e9b878d4cab873edb53d34d5b6f",
            "072f21514660489991f67ada126f3943",
            "fbf4c09f291944b99e86247605385003",
            "59a98573bd4848b386002606a48ae205",
            "5756e96951db44d0b31aaf89e82164c4",
            "ba21769828984e42b3f78212fdaaa467",
            "695e7ff67d064841bf33d8b1e7c55eb3",
            "b58b21c86fd34b0fb2d1317b111f8cd0",
            "b9dd986a0e184c3aac38b29a70f82c04",
            "4ae342cab3614ae39a36721bb0ba1ba6",
            "548978b1ecf44d0cb6e44ac78f59ca47",
            "b93d7420b02b4170bcdef01e9edd4907",
            "b7746a216e9a44cc987587a540dccb77",
            "dd7952fe331e440eac2ed0bdfdf1bf6a",
            "63dcb10ac67949dc8c729a9ed6079a8a",
            "9480764a00d046c0a1592bd7ba9e8c3e",
            "1f169a780eeb44eea8e4f869ae033176",
            "1d6d9148c0114faebd7593ed1b95368f",
            "5d1b64149acd41d8af2068750cc56950",
            "052d0d2df848417c884b6a93b9c0c81d",
            "a66bcba3be194471b31e4f90630a0461",
            "47119ee2f43242eea088271bce2ab4e4",
            "470168b4b4d949ed984d7a44a9d667b2",
            "164be652d6f54b4ea73a6c4a08e2d2f4",
            "e7cfe5724304425fa3c4b7f03dc00567",
            "1dd30a5c4fde4bc18b9c1ef609b9589e",
            "aaa8d978c89247e6a385ee1260427894",
            "61031c8937614b27be5a788a3d1e93c0",
            "84ee9c4380eb45e1868784f21accb61c",
            "27c51b9ec3f84b4f88baefc265c68149",
            "f988a1472ebe4d6c9b293a5b4ef07f8d",
            "a6a1d538b423454cbaef92ff1b72949d"
          ]
        },
        "id": "nUcp7s0wZQ-m",
        "outputId": "4587d07e-febb-403e-d263-b1aa2a7045f9"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "moving_count.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2f8ce28f23dc44eeae63060f01a7faf1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "video/clevrer.zip:   0%|          | 0.00/1.12G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "548978b1ecf44d0cb6e44ac78f59ca47"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split: 0 examples [00:00, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "47119ee2f43242eea088271bce2ab4e4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset length = 200\n",
            "Dataset length = 200\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QfYM9i_JYS-m",
        "outputId": "94e0efbf-35d1-4eab-e9bc-42c06b673587"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['answer', 'question', 'video', 'candidates'],\n",
              "    num_rows: 200\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "\n",
        "unzipped_dir = f\"{data_dir}/video/videos_unzipped\"\n",
        "video_subdir = Path(video_dir).name\n",
        "video_path = os.path.join(unzipped_dir, \"star\", video_subdir)"
      ],
      "metadata": {
        "id": "_HSIMyJnb-3Y"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "video_filename = ds[0]['video']\n",
        "full_video_path = f\"{unzipped_dir}/{video_dir}/{video_filename}\""
      ],
      "metadata": {
        "id": "yMdYh0DgdX_c"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = ds[0]['question']"
      ],
      "metadata": {
        "id": "xZlCPbI0cQFd"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir model_zoo\n",
        "!cd model_zoo\n",
        "'''\n",
        "# (Optional) Using huggingface mirrors\n",
        "!export HF_ENDPOINT=https://hf-mirror.com\n",
        "\n",
        "# download the SIGLIP model form huggingface\n",
        "!huggingface-cli download --resume-download google/siglip-so400m-patch14-384 --local-dir google/siglip-so400m-patch14-384\n",
        "\n",
        "# download enhanced baseline model from huggingface\n",
        "# 7B model\n",
        "#!huggingface-cli download --resume-download BBBBCHAN/LLaVA-Scissor-baseline-7B --local-dir LLaVA-Scissor-baseline-7B\n",
        "# 0.5B model\n",
        "!huggingface-cli download --resume-download LLaVA-Scissor-baseline-0.5B --local-dir LLaVA-Scissor-baseline-0.5B\n",
        "\n",
        "# We also support the original LLaVA-OneVision models.\n",
        "#!huggingface-cli download --resume-download LLaVA-Scissor-baseline-7B --local-dir LLaVA-Scissor-baseline-7B\n",
        "!huggingface-cli download --resume-download LLaVA-Scissor-baseline-0.5B --local-dir LLaVA-Scissor-baseline-0.5B\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "id": "nkorppRGeSwR",
        "outputId": "0d1cfbc1-1c51-407b-c9c7-2fc38c3be6f1"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n# (Optional) Using huggingface mirrors\\n!export HF_ENDPOINT=https://hf-mirror.com\\n\\n# download the SIGLIP model form huggingface\\n!huggingface-cli download --resume-download google/siglip-so400m-patch14-384 --local-dir google/siglip-so400m-patch14-384\\n\\n# download enhanced baseline model from huggingface\\n# 7B model\\n#!huggingface-cli download --resume-download BBBBCHAN/LLaVA-Scissor-baseline-7B --local-dir LLaVA-Scissor-baseline-7B\\n# 0.5B model\\n!huggingface-cli download --resume-download LLaVA-Scissor-baseline-0.5B --local-dir LLaVA-Scissor-baseline-0.5B\\n\\n# We also support the original LLaVA-OneVision models.\\n#!huggingface-cli download --resume-download LLaVA-Scissor-baseline-7B --local-dir LLaVA-Scissor-baseline-7B\\n!huggingface-cli download --resume-download LLaVA-Scissor-baseline-0.5B --local-dir LLaVA-Scissor-baseline-0.5B\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Check what's actually in model_zoo\n",
        "print(\"Current directory:\", os.getcwd())\n",
        "print(\"Contents of model_zoo:\")\n",
        "!ls -la model_zoo/\n",
        "\n",
        "# Check if we have any LLaVA models\n",
        "if os.path.exists('model_zoo'):\n",
        "    print(\"\\nSearching for model directories:\")\n",
        "    for item in os.listdir('model_zoo'):\n",
        "        item_path = os.path.join('model_zoo', item)\n",
        "        if os.path.isdir(item_path):\n",
        "            print(f\"📁 {item}\")\n",
        "            # Check if it has model files\n",
        "            model_files = [f for f in os.listdir(item_path) if f.endswith(('.bin', '.safetensors', 'config.json'))]\n",
        "            if model_files:\n",
        "                print(f\"   Model files: {model_files[:3]}...\")  # Show first 3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KLeYQuG5kiYI",
        "outputId": "42da3b86-6edb-487f-fb5b-2e42500886df"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current directory: /content\n",
            "Contents of model_zoo:\n",
            "total 8\n",
            "drwxr-xr-x 2 root root 4096 Oct 19 13:35 .\n",
            "drwxr-xr-x 1 root root 4096 Oct 19 13:35 ..\n",
            "\n",
            "Searching for model directories:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Create the correct directory structure\n",
        "os.makedirs('model_zoo/google', exist_ok=True)\n",
        "\n",
        "# Download SIGLIP to the correct location\n",
        "!hf download google/siglip-so400m-patch14-384 --local-dir model_zoo/google/siglip-so400m-patch14-384\n",
        "\n",
        "print(\"SIGLIP model downloaded successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M2aqO7FimpGg",
        "outputId": "947e57c1-ffba-4a18-df89-3f38fd5dad5b"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\rFetching 9 files:   0% 0/9 [00:00<?, ?it/s]Downloading 'spiece.model' to 'model_zoo/google/siglip-so400m-patch14-384/.cache/huggingface/download/vj8E1loknrCNPSP8nWJC234Bff4=.1e5036bed065526c3c212dfbe288752391797c4bb1a284aa18c9a0b23fcaf8ec.incomplete'\n",
            "Downloading 'tokenizer.json' to 'model_zoo/google/siglip-so400m-patch14-384/.cache/huggingface/download/HgM_lKo9sdSCfRtVg7MMFS7EKqo=.6d6fd0bd6cc263099dc98e4fa383f90c9baa3521.incomplete'\n",
            "\n",
            "\rtokenizer.json: 0.00B [00:00, ?B/s]\u001b[ADownloading 'preprocessor_config.json' to 'model_zoo/google/siglip-so400m-patch14-384/.cache/huggingface/download/PYH5dHjks7Ei0Yd3X0Z8xIwsCNQ=.051261b5a784a2e7e5f93de1f86d170d69a9efd9.incomplete'\n",
            "Downloading 'config.json' to 'model_zoo/google/siglip-so400m-patch14-384/.cache/huggingface/download/8_PA_wEVGiVa2goH2H4KQOQpvVY=.a513b447f6b05f640f9980d25f4d8a5cff6cd25d.incomplete'\n",
            "\rtokenizer.json: 2.40MB [00:00, 68.7MB/s]\n",
            "Download complete. Moving file to model_zoo/google/siglip-so400m-patch14-384/tokenizer.json\n",
            "\n",
            "\rpreprocessor_config.json:   0% 0.00/368 [00:00<?, ?B/s]\u001b[A\rpreprocessor_config.json: 100% 368/368 [00:00<00:00, 3.94MB/s]\n",
            "Download complete. Moving file to model_zoo/google/siglip-so400m-patch14-384/preprocessor_config.json\n",
            "\n",
            "\rconfig.json:   0% 0.00/576 [00:00<?, ?B/s]\u001b[A\rconfig.json: 100% 576/576 [00:00<00:00, 6.07MB/s]\n",
            "Download complete. Moving file to model_zoo/google/siglip-so400m-patch14-384/config.json\n",
            "Downloading 'model.safetensors' to 'model_zoo/google/siglip-so400m-patch14-384/.cache/huggingface/download/xGOKKLRSlIhH692hSVvI1-gpoa8=.ea2abad2b7f8a9c1aa5e49a244d5d57ffa71c56f720c94bc5d240ef4d6e1d94a.incomplete'\n",
            "\n",
            "spiece.model:   0% 0.00/798k [00:00<?, ?B/s]\u001b[ADownloading 'README.md' to 'model_zoo/google/siglip-so400m-patch14-384/.cache/huggingface/download/Xn7B-BWUGOee2Y6hCZtEhtFu4BE=.a5fd5771ea9bec56bf88604979b486b309614463.incomplete'\n",
            "Downloading 'special_tokens_map.json' to 'model_zoo/google/siglip-so400m-patch14-384/.cache/huggingface/download/ahkChHUJFxEmOdq5GDFEmerRzCY=.6555f2261d409dea394d6b6973129a53b8725803.incomplete'\n",
            "Downloading '.gitattributes' to 'model_zoo/google/siglip-so400m-patch14-384/.cache/huggingface/download/wPaCkH-WbT7GsmxMKKrNZTV4nSM=.a6344aac8c09253b3b630fb776ae94478aa0275b.incomplete'\n",
            "\n",
            "\n",
            "README.md: 4.32kB [00:00, 23.5MB/s]\n",
            "Download complete. Moving file to model_zoo/google/siglip-so400m-patch14-384/README.md\n",
            "\n",
            "\n",
            "special_tokens_map.json: 100% 409/409 [00:00<00:00, 4.89MB/s]\n",
            "Download complete. Moving file to model_zoo/google/siglip-so400m-patch14-384/special_tokens_map.json\n",
            "\n",
            "\n",
            ".gitattributes: 1.52kB [00:00, 11.4MB/s]\n",
            "Download complete. Moving file to model_zoo/google/siglip-so400m-patch14-384/.gitattributes\n",
            "Fetching 9 files:  11% 1/9 [00:00<00:01,  4.16it/s]Downloading 'tokenizer_config.json' to 'model_zoo/google/siglip-so400m-patch14-384/.cache/huggingface/download/vzaExXFZNBay89bvlQv-ZcI6BTg=.70741c5c1f6d21423ebf51ee77ef2fce868c33f2.incomplete'\n",
            "\n",
            "\n",
            "tokenizer_config.json: 100% 711/711 [00:00<00:00, 8.57MB/s]\n",
            "\n",
            "\n",
            "model.safetensors:   0% 0.00/3.51G [00:00<?, ?B/s]Download complete. Moving file to model_zoo/google/siglip-so400m-patch14-384/tokenizer_config.json\n",
            "\u001b[A\u001b[A\n",
            "spiece.model: 100% 798k/798k [00:00<00:00, 1.26MB/s]\n",
            "Download complete. Moving file to model_zoo/google/siglip-so400m-patch14-384/spiece.model\n",
            "\n",
            "\n",
            "model.safetensors:   0% 24.5k/3.51G [00:00<31:47:03, 30.7kB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:   0% 1.59M/3.51G [00:00<26:33, 2.20MB/s]   \u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:   0% 2.99M/3.51G [00:01<14:57, 3.91MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:   0% 8.09M/3.51G [00:01<06:07, 9.55MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:   1% 44.6M/3.51G [00:01<00:51, 67.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:   2% 59.2M/3.51G [00:01<00:47, 72.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:   2% 84.2M/3.51G [00:01<00:33, 102MB/s] \u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:   3% 105M/3.51G [00:01<00:29, 115MB/s] \u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:   3% 120M/3.51G [00:02<00:27, 122MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:   4% 139M/3.51G [00:04<03:02, 18.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:   4% 156M/3.51G [00:05<02:18, 24.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:   5% 178M/3.51G [00:05<01:37, 34.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:   6% 201M/3.51G [00:05<01:13, 45.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:   6% 217M/3.51G [00:05<01:00, 54.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:   7% 233M/3.51G [00:05<00:55, 59.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:   7% 256M/3.51G [00:05<00:42, 76.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:   8% 276M/3.51G [00:06<00:37, 87.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:   8% 294M/3.51G [00:06<00:33, 95.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:   9% 319M/3.51G [00:06<00:27, 115MB/s] \u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  10% 344M/3.51G [00:06<00:25, 126MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  10% 363M/3.51G [00:06<00:26, 118MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  11% 400M/3.51G [00:06<00:20, 152MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  12% 424M/3.51G [00:08<00:59, 52.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  13% 444M/3.51G [00:08<00:49, 62.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  18% 615M/3.51G [00:08<00:17, 170MB/s] \u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  18% 640M/3.51G [00:08<00:16, 170MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  19% 660M/3.51G [00:08<00:17, 159MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  19% 679M/3.51G [00:09<00:18, 153MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  20% 713M/3.51G [00:09<00:19, 144MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  21% 740M/3.51G [00:09<00:19, 145MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  22% 770M/3.51G [00:09<00:18, 150MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  22% 788M/3.51G [00:09<00:20, 136MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  23% 805M/3.51G [00:10<00:24, 110MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  24% 829M/3.51G [00:10<00:26, 101MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  24% 857M/3.51G [00:10<00:22, 117MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  25% 872M/3.51G [00:10<00:26, 97.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  26% 902M/3.51G [00:11<00:22, 118MB/s] \u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  27% 931M/3.51G [00:11<00:18, 142MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  27% 951M/3.51G [00:11<00:23, 109MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  29% 1.01G/3.51G [00:11<00:14, 172MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  29% 1.03G/3.51G [00:11<00:15, 158MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  30% 1.05G/3.51G [00:11<00:16, 147MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  31% 1.08G/3.51G [00:12<00:17, 140MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  32% 1.11G/3.51G [00:12<00:19, 124MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  32% 1.13G/3.51G [00:12<00:17, 134MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  33% 1.16G/3.51G [00:12<00:17, 134MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  34% 1.19G/3.51G [00:13<00:16, 137MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  34% 1.21G/3.51G [00:15<01:09, 33.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  35% 1.23G/3.51G [00:15<00:52, 43.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  36% 1.26G/3.51G [00:15<00:40, 55.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  36% 1.27G/3.51G [00:15<00:35, 62.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  37% 1.29G/3.51G [00:15<00:28, 76.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  38% 1.34G/3.51G [00:15<00:19, 114MB/s] \u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  39% 1.36G/3.51G [00:15<00:16, 129MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  39% 1.38G/3.51G [00:16<00:17, 120MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  40% 1.40G/3.51G [00:16<00:22, 93.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  42% 1.47G/3.51G [00:16<00:14, 137MB/s] \u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  43% 1.50G/3.51G [00:17<00:14, 136MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  43% 1.52G/3.51G [00:19<00:52, 38.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  44% 1.54G/3.51G [00:19<00:48, 41.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  44% 1.55G/3.51G [00:19<00:41, 46.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  45% 1.57G/3.51G [00:19<00:33, 58.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  45% 1.59G/3.51G [00:19<00:30, 63.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  46% 1.60G/3.51G [00:20<00:30, 63.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  47% 1.64G/3.51G [00:20<00:19, 97.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  47% 1.66G/3.51G [00:20<00:20, 88.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  48% 1.69G/3.51G [00:20<00:15, 115MB/s] \u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  49% 1.72G/3.51G [00:20<00:13, 132MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  50% 1.74G/3.51G [00:20<00:13, 135MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  50% 1.77G/3.51G [00:21<00:11, 151MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  51% 1.79G/3.51G [00:21<00:11, 153MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  52% 1.81G/3.51G [00:21<00:11, 146MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  52% 1.83G/3.51G [00:21<00:12, 134MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  53% 1.85G/3.51G [00:21<00:12, 128MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  54% 1.88G/3.51G [00:21<00:13, 118MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  54% 1.90G/3.51G [00:22<00:17, 89.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  55% 1.92G/3.51G [00:22<00:16, 97.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  56% 1.96G/3.51G [00:22<00:10, 143MB/s] \u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  57% 1.99G/3.51G [00:22<00:10, 143MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  57% 2.01G/3.51G [00:22<00:10, 139MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  58% 2.04G/3.51G [00:23<00:10, 146MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  59% 2.06G/3.51G [00:23<00:10, 145MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  59% 2.08G/3.51G [00:23<00:09, 150MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  60% 2.10G/3.51G [00:23<00:12, 111MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  61% 2.13G/3.51G [00:23<00:09, 142MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  61% 2.15G/3.51G [00:24<00:09, 136MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  62% 2.18G/3.51G [00:24<00:11, 120MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  63% 2.20G/3.51G [00:24<00:10, 128MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  63% 2.22G/3.51G [00:24<00:12, 104MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  64% 2.23G/3.51G [00:24<00:12, 103MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  64% 2.26G/3.51G [00:25<00:14, 84.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  65% 2.29G/3.51G [00:25<00:10, 112MB/s] \u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  67% 2.34G/3.51G [00:25<00:07, 154MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  67% 2.36G/3.51G [00:25<00:07, 159MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  68% 2.38G/3.51G [00:25<00:07, 146MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  68% 2.40G/3.51G [00:26<00:08, 135MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  69% 2.42G/3.51G [00:26<00:07, 141MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  69% 2.44G/3.51G [00:26<00:08, 128MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  70% 2.47G/3.51G [00:26<00:08, 125MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  71% 2.49G/3.51G [00:26<00:07, 136MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  72% 2.51G/3.51G [00:26<00:08, 123MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  72% 2.54G/3.51G [00:27<00:07, 137MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  73% 2.56G/3.51G [00:27<00:07, 122MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  73% 2.58G/3.51G [00:29<00:33, 28.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  75% 2.62G/3.51G [00:29<00:18, 47.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  76% 2.65G/3.51G [00:29<00:12, 68.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  76% 2.68G/3.51G [00:29<00:11, 70.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  77% 2.71G/3.51G [00:30<00:10, 79.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  78% 2.74G/3.51G [00:30<00:08, 92.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  79% 2.76G/3.51G [00:30<00:07, 102MB/s] \u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  79% 2.79G/3.51G [00:35<00:43, 16.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  80% 2.81G/3.51G [00:35<00:35, 19.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  80% 2.83G/3.51G [00:35<00:26, 25.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  81% 2.85G/3.51G [00:36<00:18, 35.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  82% 2.87G/3.51G [00:36<00:15, 42.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  83% 2.90G/3.51G [00:39<00:37, 16.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  83% 2.93G/3.51G [00:40<00:24, 23.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  84% 2.95G/3.51G [00:40<00:19, 29.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  85% 2.98G/3.51G [00:40<00:13, 40.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  85% 2.99G/3.51G [00:40<00:11, 46.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  86% 3.02G/3.51G [00:40<00:08, 61.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  87% 3.04G/3.51G [00:40<00:05, 80.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  87% 3.07G/3.51G [00:41<00:04, 95.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  88% 3.10G/3.51G [00:41<00:03, 103MB/s] \u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  89% 3.14G/3.51G [00:41<00:03, 109MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  91% 3.18G/3.51G [00:41<00:02, 117MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  92% 3.22G/3.51G [00:42<00:02, 143MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  92% 3.24G/3.51G [00:42<00:02, 117MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  93% 3.28G/3.51G [00:42<00:01, 120MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  94% 3.30G/3.51G [00:42<00:01, 122MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  94% 3.32G/3.51G [00:43<00:01, 121MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  95% 3.35G/3.51G [00:43<00:01, 126MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  96% 3.39G/3.51G [00:43<00:01, 125MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  97% 3.41G/3.51G [00:43<00:01, 106MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  98% 3.45G/3.51G [00:44<00:00, 127MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors: 100% 3.51G/3.51G [00:44<00:00, 78.8MB/s]\n",
            "Download complete. Moving file to model_zoo/google/siglip-so400m-patch14-384/model.safetensors\n",
            "Fetching 9 files: 100% 9/9 [00:44<00:00,  4.98s/it]\n",
            "/content/model_zoo/google/siglip-so400m-patch14-384\n",
            "SIGLIP model downloaded successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vision_tower_path = \"model_zoo/google/siglip-so400m-patch14-384\"\n",
        "print(f\"Vision tower path: {vision_tower_path}\")\n",
        "print(f\"Path exists: {os.path.exists(vision_tower_path)}\")\n",
        "\n",
        "if os.path.exists(vision_tower_path):\n",
        "    print(\"Contents of SIGLIP directory:\")\n",
        "    !ls -la {vision_tower_path}\n",
        "else:\n",
        "    print(\"❌ SIGLIP directory not found!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5CcdUBRlpJY2",
        "outputId": "a4609f8c-e167-4929-f7a7-326a71a26527"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vision tower path: model_zoo/google/siglip-so400m-patch14-384\n",
            "Path exists: True\n",
            "Contents of SIGLIP directory:\n",
            "total 3432808\n",
            "drwxr-xr-x 3 root root       4096 Oct 19 13:35 .\n",
            "drwxr-xr-x 3 root root       4096 Oct 19 13:35 ..\n",
            "drwxr-xr-x 3 root root       4096 Oct 19 13:35 .cache\n",
            "-rw-r--r-- 1 root root        576 Oct 19 13:35 config.json\n",
            "-rw-r--r-- 1 root root       1519 Oct 19 13:35 .gitattributes\n",
            "-rw-r--r-- 1 root root 3511950624 Oct 19 13:35 model.safetensors\n",
            "-rw-r--r-- 1 root root        368 Oct 19 13:35 preprocessor_config.json\n",
            "-rw-r--r-- 1 root root       4321 Oct 19 13:35 README.md\n",
            "-rw-r--r-- 1 root root        409 Oct 19 13:35 special_tokens_map.json\n",
            "-rw-r--r-- 1 root root     798330 Oct 19 13:35 spiece.model\n",
            "-rw-r--r-- 1 root root        711 Oct 19 13:35 tokenizer_config.json\n",
            "-rw-r--r-- 1 root root    2399357 Oct 19 13:35 tokenizer.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('/content/LLaVA-Scissor')\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "# Load model\n",
        "pretrained = \"BBBBCHAN/LLaVA-Scissor-baseline-0.5B\"\n",
        "model_name = \"llava_qwen\"\n",
        "device = \"cuda\"\n",
        "device_map = \"auto\"\n",
        "tokenizer, model, image_processor, max_length = load_pretrained_model(pretrained, None, model_name, device_map=device_map, attn_implementation=\"sdpa\")\n",
        "\n",
        "model.eval()\n",
        "\n",
        "def load_video(video_path, max_frames_num):\n",
        "    if type(video_path) == str:\n",
        "        vr = VideoReader(video_path, ctx=cpu(0))\n",
        "    else:\n",
        "        vr = VideoReader(video_path[0], ctx=cpu(0))\n",
        "    total_frame_num = len(vr)\n",
        "    uniform_sampled_frames = np.linspace(0, total_frame_num - 1, max_frames_num, dtype=int)\n",
        "    frame_idx = uniform_sampled_frames.tolist()\n",
        "    spare_frames = vr.get_batch(frame_idx).asnumpy()\n",
        "    return spare_frames  # (frames, height, width, channels)\n",
        "\n",
        "\n",
        "# Load and process video\n",
        "video_path = full_video_path\n",
        "video_frames = load_video(video_path, 16)\n",
        "print(video_frames.shape)\n",
        "image_tensors = []\n",
        "frames = image_processor.preprocess(video_frames, return_tensors=\"pt\")[\"pixel_values\"].half().cuda()\n",
        "image_tensors.append(frames)\n",
        "\n",
        "# Prepare conversation input\n",
        "conv_template = \"qwen_2\"\n",
        "question = f\"{DEFAULT_IMAGE_TOKEN}\\n{prompt}\\nAnswer with only a number.\"\n",
        "#question = f\"{DEFAULT_IMAGE_TOKEN}\\n{prompt}\\nAnswer options: {ds[0]['candidates'][0]}, {ds[0]['candidates'][1]}, {ds[0]['candidates'][2]}, {ds[0]['candidates'][3]}.\"\n",
        "#question = f\"{DEFAULT_IMAGE_TOKEN}\\n{prompt}.\"\n",
        "conv = copy.deepcopy(conv_templates[conv_template])\n",
        "conv.append_message(conv.roles[0], question)\n",
        "conv.append_message(conv.roles[1], None)\n",
        "prompt_question = conv.get_prompt()\n",
        "\n",
        "input_ids = tokenizer_image_token(prompt_question, tokenizer, IMAGE_TOKEN_INDEX, return_tensors=\"pt\").unsqueeze(0).to(device)\n",
        "image_sizes = [frame.size for frame in video_frames]\n",
        "\n",
        "# Generate response\n",
        "cont = model.generate(\n",
        "    input_ids,\n",
        "    images=image_tensors,\n",
        "    image_sizes=image_sizes,\n",
        "    do_sample=False,\n",
        "    temperature=0,\n",
        "    max_new_tokens=4096,\n",
        "    modalities=[\"video\"],\n",
        ")\n",
        "text_outputs = tokenizer.batch_decode(cont, skip_special_tokens=True)\n",
        "print(text_outputs[0])\n",
        "print(text_outputs[0] == ds[0]['answer'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1IUZ9dPUONGM",
        "outputId": "663968a2-4690-4e86-dce3-fea08fa1f964"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded LLaVA model: BBBBCHAN/LLaVA-Scissor-baseline-0.5B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "llava_qwen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are using a model of type qwen2 to instantiate a model of type llava_qwen. This is not supported for all configurations of models and can yield errors.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LlavaQwenConfig {\n",
            "  \"_name_or_path\": \"BBBBCHAN/LLaVA-Scissor-baseline-0.5B\",\n",
            "  \"add_faster_video\": false,\n",
            "  \"add_time_instruction\": false,\n",
            "  \"architectures\": [\n",
            "    \"LlavaQwenZipForCausalLM\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"bos_token_id\": 151643,\n",
            "  \"eos_token_id\": 151645,\n",
            "  \"faster_token_stride\": 10,\n",
            "  \"force_sample\": false,\n",
            "  \"hidden_act\": \"silu\",\n",
            "  \"hidden_size\": 896,\n",
            "  \"image_aspect_ratio\": \"anyres_max_9\",\n",
            "  \"image_crop_resolution\": null,\n",
            "  \"image_grid_pinpoints\": [\n",
            "    [\n",
            "      384,\n",
            "      384\n",
            "    ],\n",
            "    [\n",
            "      384,\n",
            "      768\n",
            "    ],\n",
            "    [\n",
            "      384,\n",
            "      1152\n",
            "    ],\n",
            "    [\n",
            "      384,\n",
            "      1536\n",
            "    ],\n",
            "    [\n",
            "      384,\n",
            "      1920\n",
            "    ],\n",
            "    [\n",
            "      384,\n",
            "      2304\n",
            "    ],\n",
            "    [\n",
            "      768,\n",
            "      384\n",
            "    ],\n",
            "    [\n",
            "      768,\n",
            "      768\n",
            "    ],\n",
            "    [\n",
            "      768,\n",
            "      1152\n",
            "    ],\n",
            "    [\n",
            "      768,\n",
            "      1536\n",
            "    ],\n",
            "    [\n",
            "      768,\n",
            "      1920\n",
            "    ],\n",
            "    [\n",
            "      768,\n",
            "      2304\n",
            "    ],\n",
            "    [\n",
            "      1152,\n",
            "      384\n",
            "    ],\n",
            "    [\n",
            "      1152,\n",
            "      768\n",
            "    ],\n",
            "    [\n",
            "      1152,\n",
            "      1152\n",
            "    ],\n",
            "    [\n",
            "      1152,\n",
            "      1536\n",
            "    ],\n",
            "    [\n",
            "      1152,\n",
            "      1920\n",
            "    ],\n",
            "    [\n",
            "      1152,\n",
            "      2304\n",
            "    ],\n",
            "    [\n",
            "      1536,\n",
            "      384\n",
            "    ],\n",
            "    [\n",
            "      1536,\n",
            "      768\n",
            "    ],\n",
            "    [\n",
            "      1536,\n",
            "      1152\n",
            "    ],\n",
            "    [\n",
            "      1536,\n",
            "      1536\n",
            "    ],\n",
            "    [\n",
            "      1536,\n",
            "      1920\n",
            "    ],\n",
            "    [\n",
            "      1536,\n",
            "      2304\n",
            "    ],\n",
            "    [\n",
            "      1920,\n",
            "      384\n",
            "    ],\n",
            "    [\n",
            "      1920,\n",
            "      768\n",
            "    ],\n",
            "    [\n",
            "      1920,\n",
            "      1152\n",
            "    ],\n",
            "    [\n",
            "      1920,\n",
            "      1536\n",
            "    ],\n",
            "    [\n",
            "      1920,\n",
            "      1920\n",
            "    ],\n",
            "    [\n",
            "      1920,\n",
            "      2304\n",
            "    ],\n",
            "    [\n",
            "      2304,\n",
            "      384\n",
            "    ],\n",
            "    [\n",
            "      2304,\n",
            "      768\n",
            "    ],\n",
            "    [\n",
            "      2304,\n",
            "      1152\n",
            "    ],\n",
            "    [\n",
            "      2304,\n",
            "      1536\n",
            "    ],\n",
            "    [\n",
            "      2304,\n",
            "      1920\n",
            "    ],\n",
            "    [\n",
            "      2304,\n",
            "      2304\n",
            "    ]\n",
            "  ],\n",
            "  \"image_split_resolution\": null,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 4864,\n",
            "  \"max_position_embeddings\": 32768,\n",
            "  \"max_window_layers\": 21,\n",
            "  \"mm_hidden_size\": 1152,\n",
            "  \"mm_newline_position\": \"grid\",\n",
            "  \"mm_patch_merge_type\": \"flat\",\n",
            "  \"mm_projector_lr\": null,\n",
            "  \"mm_projector_type\": \"mlp2x_gelu\",\n",
            "  \"mm_resampler_type\": null,\n",
            "  \"mm_spatial_pool_mode\": \"bilinear\",\n",
            "  \"mm_spatial_pool_stride\": null,\n",
            "  \"mm_tunable_parts\": \"mm_vision_tower,mm_mlp_adapter,mm_language_model\",\n",
            "  \"mm_use_im_patch_token\": false,\n",
            "  \"mm_use_im_start_end\": false,\n",
            "  \"mm_use_zip\": \"False\",\n",
            "  \"mm_vision_select_feature\": \"patch\",\n",
            "  \"mm_vision_select_layer\": -2,\n",
            "  \"mm_vision_tower\": \"model_zoo/google/siglip-so400m-patch14-384\",\n",
            "  \"mm_vision_tower_lr\": 2e-06,\n",
            "  \"model_type\": \"llava_qwen\",\n",
            "  \"num_attention_heads\": 14,\n",
            "  \"num_hidden_layers\": 24,\n",
            "  \"num_key_value_heads\": 2,\n",
            "  \"pos_skipping_range\": 4096,\n",
            "  \"rms_norm_eps\": 1e-06,\n",
            "  \"rope_scaling\": null,\n",
            "  \"rope_theta\": 1000000.0,\n",
            "  \"sliding_window\": 32768,\n",
            "  \"tie_word_embeddings\": true,\n",
            "  \"tokenizer_model_max_length\": 32768,\n",
            "  \"tokenizer_padding_side\": \"right\",\n",
            "  \"torch_dtype\": \"bfloat16\",\n",
            "  \"transformers_version\": \"4.37.2\",\n",
            "  \"use_cache\": true,\n",
            "  \"use_mm_proj\": true,\n",
            "  \"use_pos_skipping\": false,\n",
            "  \"use_sliding_window\": false,\n",
            "  \"vision_tower_pretrained\": null,\n",
            "  \"vocab_size\": 151936\n",
            "}\n",
            "\n",
            "Loading vision tower: model_zoo/google/siglip-so400m-patch14-384\n",
            "Model Class: LlavaQwenForCausalLM\n",
            "(16, 320, 480, 3)\n",
            "2\n",
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "from tqdm import tqdm\n",
        "\n",
        "comp_time = 0\n",
        "correct_guessed = 0\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "\n",
        "    for i in tqdm(range(len(ds)), desc=\"Processing samples\"):\n",
        "        sample = ds[i]\n",
        "        video_filename = sample['video']\n",
        "        full_video_path = f\"{unzipped_dir}/{video_dir}/{video_filename}\"\n",
        "        prompt = sample['question']\n",
        "        real_answer = sample['answer']\n",
        "        video_path = full_video_path\n",
        "        video_frames = load_video(video_path, 16)\n",
        "        image_tensors = []\n",
        "        frames = image_processor.preprocess(video_frames, return_tensors=\"pt\")[\"pixel_values\"].half().cuda()\n",
        "        image_tensors.append(frames)\n",
        "        conv_template = \"qwen_2\"\n",
        "        question = f\"{DEFAULT_IMAGE_TOKEN}\\n{prompt}\\nAnswer with only a number.\"\n",
        "        conv = copy.deepcopy(conv_templates[conv_template])\n",
        "        conv.append_message(conv.roles[0], question)\n",
        "        conv.append_message(conv.roles[1], None)\n",
        "        prompt_question = conv.get_prompt()\n",
        "        input_ids = tokenizer_image_token(prompt_question, tokenizer, IMAGE_TOKEN_INDEX, return_tensors=\"pt\").unsqueeze(0).to(device)\n",
        "        image_sizes = [frame.size for frame in video_frames]\n",
        "\n",
        "        start_time = time.time()\n",
        "\n",
        "        cont = model.generate(\n",
        "            input_ids,\n",
        "            images=image_tensors,\n",
        "            image_sizes=image_sizes,\n",
        "            do_sample=False,\n",
        "            temperature=0,\n",
        "            max_new_tokens=4096,\n",
        "            modalities=[\"video\"],\n",
        "        )\n",
        "        text_outputs = tokenizer.batch_decode(cont, skip_special_tokens=True)\n",
        "\n",
        "        end_time = time.time()\n",
        "        elapsed_time = end_time - start_time\n",
        "        comp_time += elapsed_time\n",
        "\n",
        "        if text_outputs[0] == real_answer:\n",
        "            correct_guessed +=1\n",
        "\n",
        "accuracy = correct_guessed / len(ds)\n",
        "print(f'Computational Time: {comp_time}\\nAccuracy: {accuracy}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P01RdCiJsh9T",
        "outputId": "bb93f39b-af11-497a-a6fb-ff411a899dbb"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing samples: 100%|██████████| 200/200 [06:44<00:00,  2.02s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Computational Time: 326.3251643180847\n",
            "Accuracy: 0.145\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "TASK_NAME = \"Action Sequence\"\n",
        "annotation_fn, video_dir, video_type, has_clip = data_list[TASK_NAME]\n",
        "\n",
        "annotation_fn_local = hf_hub_download(\n",
        "    repo_id=\"OpenGVLab/MVBench\",\n",
        "    filename='json/' + annotation_fn,\n",
        "    repo_type=\"dataset\",\n",
        "    local_dir=data_dir\n",
        ")\n",
        "\n",
        "video_zip_name = video_dir.split(\"/\")[0] + \".zip\"\n",
        "videos_zip = hf_hub_download(\n",
        "    repo_id=\"OpenGVLab/MVBench\",\n",
        "    filename='video/' + video_zip_name,\n",
        "    repo_type=\"dataset\",\n",
        "    local_dir=data_dir\n",
        ")\n",
        "\n",
        "for zip_file in os.listdir(f\"{data_dir}/video\"):\n",
        "    if zip_file.endswith(\".zip\"):\n",
        "        shutil.unpack_archive(\n",
        "            f\"{data_dir}/video/{zip_file}\",\n",
        "            f\"{data_dir}/video/videos_unzipped/\"\n",
        "        )\n",
        "\n",
        "ds = load_dataset(\"json\", data_files=annotation_fn_local, split=\"train\")\n",
        "ds\n",
        "\n",
        "has_missing = False\n",
        "for sample in ds:\n",
        "    if not os.path.exists(f\"{data_dir}/video/videos_unzipped/{video_dir}/{sample['video']}\"):\n",
        "        print(f\"Video `{sample['video']}` does not exists!\")\n",
        "        has_missing = True\n",
        "\n",
        "print(f\"Dataset length = {len(ds)}\")\n",
        "if has_missing:\n",
        "    ds = ds.filter(lambda x: os.path.exists(f\"{data_dir}/video/videos_unzipped/{video_dir}/{x['video']}\"))\n",
        "\n",
        "print(f\"Dataset length = {len(ds)}\")\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "unzipped_dir = f\"{data_dir}/video/videos_unzipped\"\n",
        "video_subdir = Path(video_dir).name\n",
        "video_path = os.path.join(unzipped_dir, \"star\", video_subdir)\n",
        "\n",
        "video_filename = ds[1]['video']\n",
        "full_video_path = f\"{unzipped_dir}/{video_dir}/{video_filename}\"\n",
        "\n",
        "prompt = ds[1]['question']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7tQiGlnDx_rM",
        "outputId": "1027b3fd-dd96-4626-bfea-108b03531ddd"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Video `EDXBD.mp4` does not exists!\n",
            "Video `K47J5.mp4` does not exists!\n",
            "Video `9MNZ5.mp4` does not exists!\n",
            "Video `QXT9W.mp4` does not exists!\n",
            "Video `ABHC6.mp4` does not exists!\n",
            "Video `ALXUC.mp4` does not exists!\n",
            "Video `BAUQE.mp4` does not exists!\n",
            "Video `PHH6B.mp4` does not exists!\n",
            "Video `MNC10.mp4` does not exists!\n",
            "Video `W7CR5.mp4` does not exists!\n",
            "Video `Q8UJ8.mp4` does not exists!\n",
            "Video `X9WTR.mp4` does not exists!\n",
            "Dataset length = 200\n",
            "Dataset length = 188\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "comp_time = 0\n",
        "correct_guessed = 0\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "\n",
        "    for i in tqdm(range(len(ds)), desc=\"Processing samples\"):\n",
        "        sample = ds[i]\n",
        "        video_filename = sample['video']\n",
        "        full_video_path = f\"{unzipped_dir}/{video_dir}/{video_filename}\"\n",
        "        prompt = sample['question']\n",
        "        real_answer = sample['answer']\n",
        "        video_path = full_video_path\n",
        "        video_frames = load_video(video_path, 16)\n",
        "        image_tensors = []\n",
        "        frames = image_processor.preprocess(video_frames, return_tensors=\"pt\")[\"pixel_values\"].half().cuda()\n",
        "        image_tensors.append(frames)\n",
        "        conv_template = \"qwen_2\"\n",
        "        question = f\"{DEFAULT_IMAGE_TOKEN}\\n{prompt}\\nChoose the correct answer:.\\n{sample['candidates'][0]}, {sample['candidates'][1]}, {sample['candidates'][2]}, {sample['candidates'][3]}\"\n",
        "        conv = copy.deepcopy(conv_templates[conv_template])\n",
        "        conv.append_message(conv.roles[0], question)\n",
        "        conv.append_message(conv.roles[1], None)\n",
        "        prompt_question = conv.get_prompt()\n",
        "        input_ids = tokenizer_image_token(prompt_question, tokenizer, IMAGE_TOKEN_INDEX, return_tensors=\"pt\").unsqueeze(0).to(device)\n",
        "        image_sizes = [frame.size for frame in video_frames]\n",
        "\n",
        "        start_time = time.time()\n",
        "\n",
        "        cont = model.generate(\n",
        "            input_ids,\n",
        "            images=image_tensors,\n",
        "            image_sizes=image_sizes,\n",
        "            do_sample=False,\n",
        "            temperature=0,\n",
        "            max_new_tokens=4096,\n",
        "            modalities=[\"video\"],\n",
        "        )\n",
        "        text_outputs = tokenizer.batch_decode(cont, skip_special_tokens=True)\n",
        "\n",
        "        end_time = time.time()\n",
        "        elapsed_time = end_time - start_time\n",
        "        comp_time += elapsed_time\n",
        "\n",
        "        if text_outputs[0] == real_answer:\n",
        "            correct_guessed +=1\n",
        "\n",
        "accuracy = correct_guessed / len(ds)\n",
        "print(f'Computational Time: {comp_time}\\nAccuracy: {accuracy}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l9DRkgB_0jHw",
        "outputId": "2419ec07-87ef-4f07-96d5-aff24f424383"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing samples: 100%|██████████| 188/188 [07:28<00:00,  2.38s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Computational Time: 324.522164106369\n",
            "Accuracy: 0.22340425531914893\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ]
}